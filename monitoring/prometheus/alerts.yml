groups:
  - name: roadtrip_api_alerts
    interval: 30s
    rules:
      # High Error Rate
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{status=~"5.."}[5m])) 
            / 
            sum(rate(http_requests_total[5m]))
          ) > 0.05
        for: 5m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes"
          
      # High Latency
      - alert: HighLatency
        expr: |
          histogram_quantile(0.95, 
            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
          ) > 2
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High latency on endpoint {{ $labels.endpoint }}"
          description: "95th percentile latency is {{ $value }}s"
          
      # Database Connection Pool Exhaustion
      - alert: DatabasePoolExhausted
        expr: |
          (
            database_pool_connections_used / database_pool_connections_max
          ) > 0.9
        for: 5m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "Database connection pool nearly exhausted"
          description: "{{ $value | humanizePercentage }} of connections are in use"
          
      # Redis Memory Usage
      - alert: RedisHighMemoryUsage
        expr: |
          (
            redis_memory_used_bytes / redis_memory_max_bytes
          ) > 0.85
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "Redis memory usage is high"
          description: "Redis is using {{ $value | humanizePercentage }} of available memory"
          
      # AI API Failures
      - alert: AIServiceFailures
        expr: |
          sum(rate(ai_requests_total{status="error"}[5m])) > 0.1
        for: 5m
        labels:
          severity: critical
          team: backend
          service: ai
        annotations:
          summary: "AI service experiencing failures"
          description: "{{ $value }} failures per second in the last 5 minutes"
          
      # Voice Processing Failures
      - alert: VoiceProcessingFailures
        expr: |
          (
            sum(rate(voice_processing_errors_total[5m]))
            /
            sum(rate(voice_processing_requests_total[5m]))
          ) > 0.1
        for: 5m
        labels:
          severity: warning
          team: backend
          service: voice
        annotations:
          summary: "High voice processing failure rate"
          description: "{{ $value | humanizePercentage }} of voice requests are failing"
          
      # Booking Service Errors
      - alert: BookingServiceErrors
        expr: |
          sum(rate(booking_errors_total[5m])) by (provider) > 0.05
        for: 5m
        labels:
          severity: warning
          team: backend
          service: booking
        annotations:
          summary: "Booking errors for provider {{ $labels.provider }}"
          description: "{{ $value }} errors per second"
          
      # Cache Hit Rate Low
      - alert: LowCacheHitRate
        expr: |
          (
            sum(rate(cache_hits_total[10m]))
            /
            sum(rate(cache_requests_total[10m]))
          ) < 0.7
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "Cache hit rate is low"
          description: "Cache hit rate is {{ $value | humanizePercentage }}"
          
      # Pod Restart
      - alert: PodRestartingTooOften
        expr: |
          increase(kube_pod_container_status_restarts_total[1h]) > 5
        labels:
          severity: warning
          team: devops
        annotations:
          summary: "Pod {{ $labels.pod }} is restarting frequently"
          description: "Pod has restarted {{ $value }} times in the last hour"
          
      # High CPU Usage
      - alert: HighCPUUsage
        expr: |
          (
            100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)
          ) > 80
        for: 10m
        labels:
          severity: warning
          team: devops
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value }}%"
          
      # Disk Space Low
      - alert: DiskSpaceLow
        expr: |
          (
            node_filesystem_avail_bytes{mountpoint="/"} 
            / 
            node_filesystem_size_bytes{mountpoint="/"} 
            * 100
          ) < 15
        for: 5m
        labels:
          severity: warning
          team: devops
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Only {{ $value }}% disk space remaining"
          
      # SSL Certificate Expiry
      - alert: SSLCertificateExpiringSoon
        expr: |
          probe_ssl_earliest_cert_expiry - time() < 86400 * 30
        for: 1h
        labels:
          severity: warning
          team: devops
        annotations:
          summary: "SSL certificate expiring soon"
          description: "Certificate expires in {{ $value | humanizeDuration }}"
          
      # Service Down
      - alert: ServiceDown
        expr: up{job=~"roadtrip.*"} == 0
        for: 2m
        labels:
          severity: critical
          team: devops
        annotations:
          summary: "Service {{ $labels.job }} is down"
          description: "{{ $labels.instance }} has been down for more than 2 minutes"
          
      # Rate Limiting Triggered
      - alert: RateLimitingHigh
        expr: |
          sum(rate(rate_limit_exceeded_total[5m])) by (endpoint) > 10
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "High rate limiting on {{ $labels.endpoint }}"
          description: "{{ $value }} rate limit hits per second"
          
      # Background Job Failures
      - alert: BackgroundJobFailures
        expr: |
          sum(rate(celery_task_failed_total[10m])) by (task) > 0.1
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "Background job {{ $labels.task }} failing"
          description: "{{ $value }} failures per second"